---
    # Run following to plot graphs of flows:
    #   ./parsley-cli.py -tasks-definition examples/example.yml -flow-definition examples/example.yml -graph ./ -v -v -v
    # you should have following files in your directory
    #   flow1.svg, flow2.svg, flow3.svg
    # In order to generate Python code for Celeriac to example.py, run:
    #   ./parsley-cli.py -tasks-definition examples/example.yml -flow-definition examples/example.yml -dump example.py -v -v -v
    #
    # Definition of tasks. For each task you have to provide name and the import that should be used in order to
    # instantiate a task. You can place tasks definition in a separate file.
    tasks:
        - name: "Task1"
          import: "worker.task1"
        - name: "Task2"
          import: "worker.task2"
        - name: "Task3"
          import: "worker.task3"
          # Optionally you can specify task class name in import, 'name' is used as a task name by default.
          classname: 'Task3Class'
          # If you want to store results and schedule new tasks based on task result, you have to provide
          # a storage, see bellow.
          storage: "storage1"
        - name: "Task4"
          # You can reuse same task implementation and name it differently in order to use a different storage for
          # results (or not to store computed results if you do not provide 'storage'). Keep in mind that output_schema,
          # time_limit and max_retry have to be shared across tasks based on same class, see bellow.
          import: "worker.task1"
          classname: "Task1"
          storage: "storage1"
        - name: "Task5"
          import: "worker.task5"
          storage: "storage2"
          # You can specify a path to a JSON schema if you want to verify task results. If the task result does not
          # conform to this schema an exception is raised and the worker fails once max_retry is reached.
          output_schema: "path/to/output/schema.json"
          # You can specify Celery's time_limit that will be set by Celeriac for the task. Keep in mind that
          # this limit is applicable on task class level - so if you create multiple tasks of the same type, they must
          # obey same time_limit. If not set, it defaults to 3600.
          time_limit: 3600
          # no limit would be:
          #   time_limit:
          # You can also specify how many times could be a task retried if it fails. The configuration is also
          # applicable on task class level as in time_limit case. If not set, it defaults to 1. Failures are
          # propagated, so if a task fails in a subflow, the whole flow fails as well.
          max_retry: 2
          # no limited retry would be:
          #   max_retry:


    # Since we can use cyclic dependencies, we have to provide listing of all flows and tasks that our system has.
    flows:
        - "flow1"
        - "flow2"
        - "flow3"


    # If you want to make decisions on when to run which task based on its results and store computed results, you have
    # to provide a definition of a storage that should be used with all the details how to connect to it. Each storage
    # is named and you can use this name to refer to the particular storage in tasks definition. Fields 'import' and
    # 'classname' have similar meaning as in case of tasks definition - Python's import path and class name (which
    # defaults to name field if not provided explicitly). The implementation of storage has to conform to Celeriac's
    # DataStorage, so configuration is specific to your implementation of Celeriac's DataStorage (see Celeriac for
    # more info).
    storages:
        - name: "storage1"
          import: "storage.storage1"
          classname: "Storage1"
          # The configuration to Storage1 will be passed as:
          #   ds = Storage1()
          #   ds.connect(username="scams", password="shadowedentity",
          #              connection=[{"port": 5432, "host": "os1.socuc.lan"}, {"port": 5432, "host": "os2.socuc.lan"},]
          # The configuration is highly specific to your DataStorage implementation and can consist of anything you
          # choose. For example, there are listed multiple connections in case of os1.socuc.lan will not be available
          # your implementation will fallback to os2.socuc.lan.
          configuration:
            username: "scams"
            password: "shadowedentity"
            connection:
                - port: 5432
                  host: "os1.socuc.lan"
                - port: 5432
                  host: "os2.socuc.lan"

        - name: "storage2"
          import: "storage.storage2"
          # if classname if omitted, 'name' will be used:
          #classname: "storage2"
          configuration:
            username: "bae"
            password: "imissmybae"
            connection:
              port: 5432
              host: "socuc.lan"


    # 'flow-definition' can be in a separate file (or split across multiple files) if you want to have task
    # definition and flow definition separated.

    # Now we have to define each flow:
    flow-definitions:
        - name: "flow1"
            # The following describes following simple flow (from Task1 to Task2):
            #    Task1
            #      |
            #      |
            #    Task2
            #
            # Each flow consists of edges.
          edges:
              # We have to specify a source, a destination node and a condition for the edge. Fields
              # 'from' and 'to' can refer to tasks or flows. The condition consists of an
              # predicate - if True, desired task 'Task2' is run.
              - from: "Task1"
                to: "Task2"
                condition:
                    name: "alwaysTrue"
              - to: "Task1"
                # If we do not specify 'from', edge is treated as a starting edge of the flow. Each flow has to
                # provide at least one starting edge.
                from:
                condition:
                    name: "alwaysTrue"
            # Note that if we do not provides 'args' argument in Celeriac, the result of Task1 will be propagated as
            # an argument to Task2.

        - name: "flow2"
          edges:
              # The following describes nested flow:
              #      Task3
              #        | if for the result of Task3 applies: result['foo']['bar'] == 'baz'
              #       /\
              #      /  \
              #     /    \
              #  Task4   flow1
              #    \      /
              #     \    /
              #      \  /
              #       \/
              #        |
              #        | if for the result of Task4 applies: (not result['foo'] is True) and result['bar'] > 5
              #        |
              #      Task5
              # First, let's define the starting edge:
              - from:
                to: "Task3"
                condition:
                    # The starting edge cannot inspect any result, since there are no previous tasks in from.
                    name: "alwaysTrue"
              # After the Task3 is done, start Task4 and flow1:
              - from: "Task3"
                to:
                    # we provide a list of tasks that should be run if condition is satisfied:
                    - "Task4"
                    - "flow1"
                condition:
                    name: "fieldEqual"
                    # We provide a list of keys in order to access nested values in dicts:
                    args:
                        key:
                            - "foo"
                            - "bar"
                        value: "baz"
              # Similarly we can wait for both tasks to finish. If we do not depend on flow1, we could simply
              # omit "flow1" from 'from' and we would not wait for 'flow1' to be finished as shown in flow3.
              - from:
                  - "Task4"
                  - "flow1"
                to: "Task5"
                condition:
                    # You can use n-ary 'and' and 'or' logical operators as you would expect. Similarly you can use
                    # unary 'not' operator (you could simple change value to 'false', but we want to demonstrate 'not')
                    and:
                        - not:
                            name: "fieldEqual"
                            # Since we have multiple dependencies in 'from', we have to explicitly refer to node that
                            # condition should apply to.
                            node: "Task4"
                            args:
                                key: "foo"
                                value: true
                        - name: "fieldGreater"
                          node: "Task4"
                          args:
                              key: "bar"
                              value: 5
        - name: "flow3"
          edges:
              # The following describes:
              #
              #                              |-------> Task3
              #                              |           | if for the result of Task3 applies: result['foo']['bar'] == 'baz'
              #                              |          /\
              #                              |         /  \
              #                              |        /    \
              #                              |     Task4   flow1
              #   result['foo'] is not None  |       |
              #                              |       |
              #                              |       | if for the result of Task4 applies: (not result['foo'] is True) and result['bar'] > 5
              #                              |----- Task5
              #
              # This example is same as for flow2, but we are not waiting for flow1 to be finished and we start
              # Task3 again if the result['foo'] of Task5 is not None
              - from:
                to: "Task3"
                condition:
                    name: "alwaysTrue"
              - from: "Task3"
                to:
                    - "Task4"
                    - "flow1"
                condition:
                    name: "fieldEqual"
                    node: "Task3"
                    args:
                        key:
                            - "foo"
                            - "bar"
                        value: "baz"
              - from: "Task4"
                to: "Task5"
                condition:
                    and:
                        - not:
                            name: "fieldEqual"
                            node: "Task4"
                            args:
                                key: "foo"
                                value: true
                        - name: "fieldGreater"
                          node: "Task4"
                          args:
                              key: "bar"
                              value: 5
              # Cyclic dependencies are intuitive and can be applied for any node - for a flow or a task.
              - from: "Task5"
                to: "Task3"
                condition:
                    not:
                        name: "fieldNone"
                        args:
                            key: 'foo'

